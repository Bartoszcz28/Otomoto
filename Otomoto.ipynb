{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4823724e",
   "metadata": {},
   "source": [
    "# Web scraping Otomoto\n",
    "The program that collects data from the Otodom website (https://www.otomoto.pl/) and saves in a csv file and access to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2ea2f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (1.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.9/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.9/site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /opt/conda/lib/python3.9/site-packages (from pandas) (1.20.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (2.25.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.9/site-packages (from requests) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests) (2020.12.5)\n",
      "Requirement already satisfied: bs4 in /opt/conda/lib/python3.9/site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.9/site-packages (from bs4) (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.9/site-packages (from beautifulsoup4->bs4) (2.0.1)\n",
      "Requirement already satisfied: plotly in /opt/conda/lib/python3.9/site-packages (5.1.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from plotly) (1.16.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.9/site-packages (from plotly) (8.0.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (1.20.3)\n",
      "Requirement already satisfied: geopy in /opt/conda/lib/python3.9/site-packages (2.2.0)\n",
      "Requirement already satisfied: geographiclib<2,>=1.49 in /opt/conda/lib/python3.9/site-packages (from geopy) (1.52)\n",
      "Requirement already satisfied: html5lib in /opt/conda/lib/python3.9/site-packages (1.1)\n",
      "Requirement already satisfied: six>=1.9 in /opt/conda/lib/python3.9/site-packages (from html5lib) (1.16.0)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.9/site-packages (from html5lib) (0.5.1)\n",
      "Requirement already satisfied: sqlalchemy==1.3.9 in /opt/conda/lib/python3.9/site-packages (1.3.9)\n",
      "Requirement already satisfied: ipython-sql in /opt/conda/lib/python3.9/site-packages (0.4.0)\n",
      "Requirement already satisfied: ipython-genutils>=0.1.0 in /opt/conda/lib/python3.9/site-packages (from ipython-sql) (0.2.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from ipython-sql) (1.16.0)\n",
      "Requirement already satisfied: ipython>=1.0 in /opt/conda/lib/python3.9/site-packages (from ipython-sql) (7.23.1)\n",
      "Requirement already satisfied: prettytable<1 in /opt/conda/lib/python3.9/site-packages (from ipython-sql) (0.7.2)\n",
      "Requirement already satisfied: sqlparse in /opt/conda/lib/python3.9/site-packages (from ipython-sql) (0.4.1)\n",
      "Requirement already satisfied: sqlalchemy>=0.6.7 in /opt/conda/lib/python3.9/site-packages (from ipython-sql) (1.3.9)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.9/site-packages (from ipython>=1.0->ipython-sql) (0.1.2)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.9/site-packages (from ipython>=1.0->ipython-sql) (49.6.0.post20210108)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.9/site-packages (from ipython>=1.0->ipython-sql) (2.9.0)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.9/site-packages (from ipython>=1.0->ipython-sql) (0.7.5)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.9/site-packages (from ipython>=1.0->ipython-sql) (0.2.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from ipython>=1.0->ipython-sql) (3.0.18)\n",
      "Requirement already satisfied: traitlets>=4.2 in /opt/conda/lib/python3.9/site-packages (from ipython>=1.0->ipython-sql) (5.0.5)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.9/site-packages (from ipython>=1.0->ipython-sql) (4.8.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.9/site-packages (from ipython>=1.0->ipython-sql) (5.0.9)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.9/site-packages (from ipython>=1.0->ipython-sql) (0.18.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.9/site-packages (from jedi>=0.16->ipython>=1.0->ipython-sql) (0.8.2)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.9/site-packages (from pexpect>4.3->ipython>=1.0->ipython-sql) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.9/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=1.0->ipython-sql) (0.2.5)\n",
      "Requirement already satisfied: psycopg2-binary in /opt/conda/lib/python3.9/site-packages (2.9.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install requests\n",
    "!pip install bs4\n",
    "!pip install plotly\n",
    "!pip install numpy\n",
    "!pip install geopy\n",
    "!pip install html5lib\n",
    "!pip install sqlalchemy==1.3.9\n",
    "!pip install ipython-sql\n",
    "!pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa79468c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from IPython.display import clear_output\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "from geopy.geocoders import Nominatim\n",
    "import html5lib\n",
    "import psycopg2\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6a4dc1",
   "metadata": {},
   "source": [
    "Load data from json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a5f2bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Data_to_Otomoto.json') as file:\n",
    "    Data_to_Otomoto = json.loads(file.read())\n",
    "\n",
    "insert_table = Data_to_Otomoto[\"insert_table\"]\n",
    "car_brand = Data_to_Otomoto[\"car_brand\"]\n",
    "table_cars = Data_to_Otomoto[\"table_cars\"]\n",
    "CREATE_TABLE = Data_to_Otomoto[\"CREATE_TABLE\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20df65ce",
   "metadata": {},
   "source": [
    "Addition of the euro exchange rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6763d91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.6330 \n"
     ]
    }
   ],
   "source": [
    "html_data_eur = requests.get(\"https://www.bankier.pl/waluty/kursy-walut/forex/eurpln\")\n",
    "soup = BeautifulSoup(html_data_eur.content, 'html5lib')\n",
    "eur = soup.find('div',attrs={\"class\":\"profilLast\"}).text\n",
    "eur = eur.replace(\",\",\".\")\n",
    "print(eur)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7339505b",
   "metadata": {},
   "source": [
    "Adding a function that retrieves the price clears the data, if the price is in EUR, it converts it to PLN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf3028d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_price(soup):\n",
    "    Cena = soup.find('span',attrs={\"class\":\"offer-price__number\"}).text\n",
    "    Cena = Cena.replace(\" \",\"\").replace(\",\",\".\")\n",
    "    if \"PLN\" in Cena:\n",
    "        Cena = Cena.replace(\"PLN\",\"\")\n",
    "        Cena = float(Cena)\n",
    "    elif \"EUR\" in Cena:\n",
    "        Cena = Cena.replace(\"EUR\",\"\")\n",
    "        Cena = float(Cena)\n",
    "        Cena = Cena * eur\n",
    "    else:\n",
    "        Cena = np.NaN\n",
    "    return Cena"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967ca5f5",
   "metadata": {},
   "source": [
    "A function that gets the ID of the advertisement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f074885a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_id(soup):\n",
    "    ID = soup.find('div',attrs={\"class\":\"offer-content__metabar\"})\n",
    "    ID = ID.find('div')\n",
    "    ID = ID.find('span',attrs={\"id\":\"ad_id\"}).text\n",
    "    return ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7d07ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_localization(soup):\n",
    "    try:\n",
    "        localization = soup.find('a',attrs={\"class\":\"seller-card__links__link__cta\"}).text.strip()\n",
    "        locator = Nominatim(user_agent=\"myGeocoder\") \n",
    "        location = locator.geocode(localization)\n",
    "        latitude = location.latitude\n",
    "        longitude = location.longitude\n",
    "    except:\n",
    "        localization = np.nan\n",
    "        latitude = np.nan\n",
    "        longitude = np.nan\n",
    "        \n",
    "    return localization, latitude, longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56d9fa15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Poznań, Wielkopolskie, Stare Miasto', 52.4087213, 16.9336538)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_data = requests.get(\"https://www.otomoto.pl/oferta/mercedes-benz-gla-serwisowany-aso-polski-salon-prywatnie-ID6DXUZi.html\")\n",
    "soup = BeautifulSoup(html_data.content, 'html5lib')\n",
    "take_localization(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c23236",
   "metadata": {},
   "source": [
    "Getting details and cleaning them. Then save the data to the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1d17cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_details(soup):\n",
    "    details = {}    \n",
    "    for info in soup.find_all('li',attrs={\"class\":\"offer-params__item\"}):\n",
    "        key = info.find('span').text.strip().replace(\" \",\"_\").replace(\"(\",\"\").replace(\")\",\"\")\n",
    "        key = key.replace(\"ś\",\"s\").replace(\"ż\",\"z\").replace(\"ó\",\"o\").replace(\"ć\",\"c\").replace(\"ę\",\"e\")\n",
    "        key = key.replace(\"ł\",\"l\").replace(\"ą\",\"a\")\n",
    "        if key in insert_table:\n",
    "            value = info.find('div').text.strip()\n",
    "            details[key] = value\n",
    "    return details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7510f915",
   "metadata": {},
   "source": [
    "Combine all data into one dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d512ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_all(soup):\n",
    "    dict_all = {}\n",
    "    dict_all[\"ID\"] = take_id(soup)\n",
    "    dict_all[\"Cena\"] = get_price(soup)\n",
    "#         dict_all[\"localization\",\"latitude\",\"longitude\"] = take_localization(soup)\n",
    "    texts = [\"localization\",\"latitude\",\"longitude\"]\n",
    "    for (x, y) in zip(texts, take_localization(soup)): \n",
    "        dict_all[x] = y\n",
    "    details = take_details(soup)\n",
    "    return dict_all | details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc5e0360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ID': '6087354512',\n",
       " 'Cena': 75000.0,\n",
       " 'localization': 'Poznań, Wielkopolskie, Stare Miasto',\n",
       " 'latitude': 52.4087213,\n",
       " 'longitude': 16.9336538,\n",
       " 'Oferta_od': 'Osoby prywatnej',\n",
       " 'Kategoria': 'Osobowe',\n",
       " 'Marka_pojazdu': 'Mercedes-Benz',\n",
       " 'Model_pojazdu': 'GLA',\n",
       " 'Wersja': '250 4-Matic',\n",
       " 'Rok_produkcji': '2014',\n",
       " 'Przebieg': '176 000 km',\n",
       " 'Pojemnosc_skokowa': '1 991 cm3',\n",
       " 'Rodzaj_paliwa': 'Benzyna',\n",
       " 'Moc': '211 KM',\n",
       " 'Skrzynia_biegow': 'Automatyczna',\n",
       " 'Naped': '4x4 (stały)',\n",
       " 'Spalanie_W_Miescie': '8 l/100km',\n",
       " 'Typ_nadwozia': 'SUV',\n",
       " 'Emisja_CO2': '154 g/km',\n",
       " 'Liczba_drzwi': '5',\n",
       " 'Liczba_miejsc': '5',\n",
       " 'Kolor': 'Niebieski',\n",
       " 'Rodzaj_koloru': 'Metalik',\n",
       " 'Kraj_pochodzenia': 'Polska',\n",
       " 'Numer_rejestracyjny_pojazdu': 'PO7LS08',\n",
       " 'Zarejestrowany_w_Polsce': 'Tak',\n",
       " 'Serwisowany_w_ASO': 'Tak',\n",
       " 'Stan': 'Używane'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "take_all(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff76df76",
   "metadata": {},
   "source": [
    "Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92e68267",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_clean(details):\n",
    "    try:\n",
    "        details['Przebieg'] = details['Przebieg'][:-2].replace(\" \",\"\")\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        details['Moc'] = details['Moc'][:-2].replace(\" \",\"\").replace(\",\",\".\")\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        details['Pojemnosc_skokowa'] = details['Pojemnosc_skokowa'][:-3].replace(\" \",\"\").replace(\",\",\".\")\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        details['Spalanie_W_Miescie'] = details['Spalanie_W_Miescie'][:-7].replace(\" \",\"\").replace(\",\",\".\")\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        details['Spalanie_W_Cyklu_Mieszanym'] = details['Spalanie_W_Cyklu_Mieszanym'][:-7].replace(\" \",\"\").replace(\",\",\".\")\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        details['Spalanie_Poza_Miastem'] = details['Spalanie_Poza_Miastem'][:-7].replace(\" \",\"\").replace(\",\",\".\")\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        details['Emisja_CO2'] = details['Emisja_CO2'][:-4].replace(\" \",\"\").replace(\",\",\".\")\n",
    "    except:\n",
    "        pass\n",
    "    return details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93680209",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_list = ['Cena','Moc','Pojemnosc_skokowa','Liczba_drzwi','Przebieg','Rok_produkcji',\n",
    "             'Spalanie_W_Miescie','Emisja_CO2','Liczba_miejsc','Spalanie_W_Cyklu_Mieszanym',\n",
    "             'Spalanie_Poza_Miastem']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a42bd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_cars = pd.DataFrame(table_cars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6b36b6",
   "metadata": {},
   "source": [
    "## Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cefeb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read_announcements  26624\n",
      "https://www.otomoto.pl/oferta/bmw-x1-sdrive-18d-xline-150km-navi-oplacony-ID6E7gr6.html#c6b14bc329\n"
     ]
    }
   ],
   "source": [
    "Link_ERROR = 0\n",
    "Read_announcements = 0\n",
    "new_row = {}\n",
    "all_data = []\n",
    "for brand in car_brand:\n",
    "    brand_link = f\"https://www.otomoto.pl/osobowe/{brand}/?search%5Border%5D=created_at%3Adesc&page=\"\n",
    "    for page_main in range(1,501): \n",
    "        try:\n",
    "            html_data_link = requests.get(brand_link + str(page_main))\n",
    "            if brand in html_data_link.url:       \n",
    "                soup_url = BeautifulSoup(html_data_link.content, 'html5lib')\n",
    "                links = []\n",
    "                for offer in soup_url.find_all('a',attrs={\"class\":\"offer-title__link\"}):\n",
    "                    if \"https://www.otomoto.pl\" in offer['href']:\n",
    "                        links.append(offer['href']) \n",
    "                for page in links:\n",
    "                    print(page)\n",
    "                    html_data = requests.get(page)\n",
    "                    soup = BeautifulSoup(html_data.content, 'html5lib')\n",
    "                    dict_all = take_all(soup)\n",
    "                    dict_all = data_clean(dict_all)\n",
    "                    dict_all[\"Link\"] = page\n",
    "                    if dict_all:\n",
    "                        all_data.append(dict_all)\n",
    "                    Read_announcements += 1\n",
    "                    clear_output(wait=True)\n",
    "                    print(\"Read_announcements \", Read_announcements) \n",
    "        except Exception:\n",
    "            print(\"Link_ERROR\")\n",
    "            continue\n",
    "table_cars = table_cars.append(all_data, ignore_index=True)\n",
    "#table_cars = pd.DataFrame.from_dict(all_data, orient='columns')\n",
    "delete_duplicates = Read_announcements - len(table_cars.index) \n",
    "print(\"Delete duplicates: \", delete_duplicates)\n",
    "print(\"Finish\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d0a7f7",
   "metadata": {},
   "source": [
    "Checking the data type if the type does not match then write nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b5cb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in table_cars.index:\n",
    "    for col in type_list:\n",
    "        cel = table_cars.at[row,col]\n",
    "        try:\n",
    "            cel = float(cel)\n",
    "        except:\n",
    "            table_cars.at[row,col] = np.nan\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68e034c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #GIT\n",
    "# Link_ERROR = 0\n",
    "# Read_announcements = 0\n",
    "# new_row = {}\n",
    "# all_data = []\n",
    "# for page_main in range(1,4):  \n",
    "#     try:\n",
    "#         html_data_link = requests.get(f\"https://www.otomoto.pl/osobowe/?search%5Border%5D=created_at%3Adesc&page={page_main}\")\n",
    "#         soup_url = BeautifulSoup(html_data_link.content, 'html5lib')\n",
    "#     except Exception:\n",
    "#         print(\"Link_ERROR\")\n",
    "#         continue\n",
    "#     links = []\n",
    "#     for offer in soup_url.find_all('a',attrs={\"class\":\"offer-title__link\"}):\n",
    "#         if \"https://www.otomoto.pl\" in offer['href']:\n",
    "#             links.append(offer['href']) \n",
    "#     for page in links:\n",
    "#         html_data = requests.get(page)\n",
    "#         soup = BeautifulSoup(html_data.content, 'html5lib')\n",
    "#         dict_all = take_all(soup)\n",
    "#         dict_all = data_clean(dict_all)\n",
    "#         all_data.append(dict_all)\n",
    "#         Read_announcements += 1\n",
    "#         clear_output(wait=True)\n",
    "#         print(\"Read_announcements \", Read_announcements)\n",
    "# table_cars = pd.DataFrame.from_dict(all_data, orient='columns')\n",
    "# delete_duplicates = Read_announcements - len(table_cars.index) \n",
    "# print(\"Delete duplicates: \", delete_duplicates)\n",
    "# print(\"Finish\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbab127",
   "metadata": {},
   "source": [
    "Adding the file name and database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d29165c",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = 'Otomoto_full'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee39c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_cars.to_csv (table_name +'.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b5931a",
   "metadata": {},
   "source": [
    "Connecting to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffd1414",
   "metadata": {},
   "outputs": [],
   "source": [
    "psql = psycopg2.connect(host='192.168.10.163', port='5432', database='Otomoto', user='barto', password='biznes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10edffa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = psql.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74396d69",
   "metadata": {},
   "source": [
    "Deleting an existing table and creating a new table in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7754e051",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute('DROP TABLE IF EXISTS '+ table_name)\n",
    "createTableCommand = 'CREATE TABLE ' + table_name + CREATE_TABLE \n",
    "cur.execute(createTableCommand)\n",
    "psql.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120bb468",
   "metadata": {},
   "source": [
    "Loop that loads data into the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d677160",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0\n",
    "for row in table_cars.itertuples(index=False):\n",
    "    full=\"\"\n",
    "    full_fit=\"INSERT INTO \" + table_name + \"(\"\n",
    "    for (column, insert) in zip(row, insert_table):\n",
    "        if str(column) =='nan':\n",
    "            continue\n",
    "        column = str(column)\n",
    "        column = column.replace(\"'\", \"''\")\n",
    "        full +=\"'\"+column+\"'\"+\", \"\n",
    "        full_fit += insert + ', '  \n",
    "        \n",
    "    full=full[:-2]\n",
    "    full_fit=full_fit[:-2]\n",
    "    full_fit=full_fit+')'\n",
    "    Value_data='VALUES ('+full+') ON CONFLICT DO NOTHING;'\n",
    "    insertDataCommand = full_fit+\"\\r\\n\"+Value_data\n",
    "    \n",
    "    cur.execute(insertDataCommand)\n",
    "psql.commit()\n",
    "print(\"Finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08765905",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
